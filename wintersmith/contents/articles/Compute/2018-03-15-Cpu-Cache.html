---
date: 2018-03-15 03:43:32
template: tech.jade
title: Cpu Cache
category: Compute
chage_frequency: monthly
tag: hardware,cpu,cache
---
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#sec-1">Cpu Cache</a></li>
<li><a href="#sec-2">memory barrier</a></li>
<li><a href="#sec-3">refrent</a></li>
</ul>
</div>
</div>

<div id="outline-container-sec-1" class="outline-2">
<h2 id="sec-1">Cpu Cache</h2>
<div class="outline-text-2" id="text-1">
<p>
Cpu Cache是为了加速Cpu访问主存储 （memory）的速度,下面是一个Intel core i7处理器官方手册给出的Cpu指标：
</p>
<blockquote>
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="left" />

<col  class="left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="left">Data Source</th>
<th scope="col" class="left">Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td class="left">local  L1 CACHE hit</td>
<td class="left">~4 cycles (2.1 - 1.2 ns)</td>
</tr>

<tr>
<td class="left">local  L2 CACHE hit</td>
<td class="left">~10 cycles (5.3 - 3.0 ns)</td>
</tr>

<tr>
<td class="left">L3 CACHE hit, line unshared</td>
<td class="left">~40 cycles (21.4 - 12.0 ns)</td>
</tr>

<tr>
<td class="left">L3 CACHE hit, shared line in another core</td>
<td class="left">~65 cycles (34.8 - 19.5 ns)</td>
</tr>

<tr>
<td class="left">L3 CACHE hit, modified in another core</td>
<td class="left">~75 cycles (40.2 - 22.5 ns)</td>
</tr>

<tr>
<td class="left">remote L3 CACHE</td>
<td class="left">~100-300 cycles (160.7 - 30.0 ns)</td>
</tr>

<tr>
<td class="left">Local Dram</td>
<td class="left">~60 ns</td>
</tr>

<tr>
<td class="left">Remote Dram</td>
<td class="left">~100 ns</td>
</tr>
</tbody>
</table>
</blockquote>

<p>
在smp（对称多处理）架构中，多个cpu core共享一个内存:
<img src="../../img/smp-cpu-arch.png" alt="smp-cpu-arch.png" />
而cache是位于cpu中的，故存在同一份内存被cache在多个cpu的cache Line中，故而需要保证cache的透明性，所以有了cache一致性协议。
</p>

<p>
cache一致性协议比较广泛使用的是MESI的协议，每个cacheLine有如下的状态：
</p>

<ul class="org-ul">
<li>M (modified)  修改过，与主存不一致，别的cache中应为Invalid
</li>
<li>E（exclusive) 其它cache中没有，仅本cpu有，其它cache如果读取，则需要从本cache传递给它
</li>
<li>S（shared）存在于多个cache中，和主存中内容一致
</li>
<li>I（invalid）cache中内容无效，是陈旧的，如已经被别的cpu修改
</li>
</ul>

<p>
cache的状态转换如下图
</p>


<div class="figure">
<p><img src="../../img/cache-consistency.png" alt="cache-consistency.png" />
</p>
</div>

<p>
仅仅依靠cache一致性协议，还太简单，因为在cache失效的时候，必须等待别的cpu完成失效，然后应答发起失效的cpu，这是一种同步通信，会导致性能非常低下，
而为了提升性能，在某些情况下，做了一些优化：
</p>


<div class="figure">
<p><img src="../../img/cache-with-store-buffer-invalid-queue.png" alt="cache-with-store-buffer-invalid-queue.png" />
</p>
</div>

<ul class="org-ul">
<li>在修改时，发送invalid请求给其它cpu，但不等待别的cpu应答完成而直接将结果写入自己的store buffer，不修改cacheLine
</li>
<li>当别的cpu完成失效，本cpu收到所有cpu的失效应答后，将store buffer中的内容写出cacheLine，标记为Modified，表示做了修改
</li>
<li>在invalid请求到达时，本地cpu并不同步进行失效，而是放入 invalid queue，然后立即应答失效给发起cpu，这样加快了失效的过程
</li>
</ul>

<p>
在经过改进后，本地的任何读取，都要先检查store buffer中是否有，如果有从store buffer读取，否则再走原来的读取逻辑，这叫做 store buffer 的 read forword。
</p>
</div>
</div>

<div id="outline-container-sec-2" class="outline-2">
<h2 id="sec-2">memory barrier</h2>
<div class="outline-text-2" id="text-2">
<p>
在改进后的cache一致性架构中，提升性能的同时，引入了不安全性。
如，由于cache失效后并未写入cacheLine和同步等待别的cpu失效其cache，如果处于invalid queue中，那么别的cpu读取就是陈旧的值。
而如果在本地两次更新中，如果第二次的更新cache状态是exclusive和第一次是非exclusive和modified等，那么第二次更新可能先于第一次而被别的cpu看到。这违反了顺序性。
</p>

<p>
根本原因在于，cache的更新失效并未同步完成，而异步的进行，导致了生效时刻的乱序。
</p>

<p>
在需要多线程并发执行的情形下，如果需要保证因果性，线性化，则引入memory barrier来使得这种优化退化到简单的MESI情况。
</p>

<ul class="org-ul">
<li>store barrier<br  />
  保证任何barrier之前的写入都已经同步到其它cache上，已经cache一致，然后barrier后面的写入才同步到其它cacache上。维持了一种可见性顺序与program的顺序的一致性。
如果 <b>write a -&gt; store barrier -&gt; write b</b> 那么当我看到b被修改时，我一定看到了a被修改。
</li>
<li>load barrier<br  />
  保证任何barrier之前的读取同步都发生于barrier之后的读取同步。
如果 <b>read a -&gt; load barrier -&gt; read b</b> ，a的值是读取b时最新的值。
</li>
</ul>
</div>
</div>

<div id="outline-container-sec-3" class="outline-2">
<h2 id="sec-3">refrent</h2>
<div class="outline-text-2" id="text-3">
<ul class="org-ul">
<li><a href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf">Intel cpu manual</a>
</li>
<li><a href="http://www.rdrop.com/users/paulmck/scalability/paper/whymb.2010.07.23a.pdf">memory barrier: a hardware view for software hackers</a>
</li>
<li><a href="https://www.akkadia.org/drepper/cpumemory.pdf">What Every Programmer Should Know About Memory</a>
</li>
</ul>
</div>
</div>
