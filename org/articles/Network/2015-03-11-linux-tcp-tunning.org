#+BEGIN_HTML
---
date: 2015-03-11 22:05:08
template: tech.jade
title: Linux Tcp 参数调优
category: Network
chage_frequency: monthly
tag: Linux
---
#+END_HTML
#+OPTIONS: toc:nil
#+TOC: headlines 2
TCP 参数在这里做一个汇总，和清楚明白的说明，希望能够指导进行网络程序优化，同时做一个备忘。

*** 半连接
半连接可以指握手还没有结束，或者挥手还没有结束。
    
在挥手还没有结束的适合，发出fin包得一方不再能发送数据，但是还是可以收到对方发来的数据。
*** 网络分片与重组
**** link 层 —— Frame
1542 byte
**** ip 层 
MTU : max transimit Unit —— 1500 byte

- ip 会进行重组, 在到达目标主机的时候，向上层发出之前重组。
- 网络中的路由器可能对于大于自己支持MTU的报文进行丢失，因为重组后，切片影响性能。
**** tcp 层
MSS : max segment size —— 1460
tcp 是面向字节流的，一个tcp报文最大传输的大小由此参数控制，MSS在主机上面配置。

UDP 面向数据报，不会分段。
**** tcp_mtu_probing
     tcp 层面的mtu发现（PLPMTUD），初始tcp MSS 为 /tcp_base_mss/
**** tcp_base_mss
     初次尝试的mss大小（512）,不断增大
*** 新建链接
**** tcp_max_syn_backlog
半链接缓冲队列长度。指还没有收到ack的连接
**** somaxconn
处于listen状态单个端口上面accept队列长度。
**** tcp_synack_retries
链接被动打开方的确认链接的应答最大重试次数。
**** tcp_syncookies
开启此功能，防止sync flood攻击，在将链接加入syn_backlog之前先发出syn并带上cookies。
**** tcp_syn_retries
链接主动打开方的syn尝试次数
**** tcp_abort_on_overflow
如果上层accept应用无法处理过来，就对新来的connection直接rst。
*** 传输过程中
**** tcp_window_scaling
调整window大小，针对更大的tcp报文——大于64k。
**** tcp_congestion_control
拥塞控制算法。默认的算法是慢启动——线性增大，快减少——重传超时指数后退，丢包重传减半。
**** tcp_retrans_collapse
重传合并
**** tcp_retries1
进行重传的次数，超过这个次数后进入第二阶段的重传，这个阶段假设网络是ok的
**** tcp_retries2
第二阶段的重传，重传次数增加。
*** 链接断开
**** tcp_orphan_reties
探测对端已经close的次数
**** tcp_max_orphans
最大孤儿socket，孤儿socket没有与fd关联，每个孤儿socket会占用64k不可交换内存。
**** tcp_fin_timeout
处于FIN2_WAIT时等待对方发送FIN包得时间，单位是秒，默认60s，超过此时间强制关闭连接。     
**** tcp_tw_recycle = 0
启用  =TIME_WAIT=  状态SOCKET的回收，更激进的重复使用 =TIME_WAIT= 状态的SOCKET，对于处于NAT和LB等设备后面经过地址转换的链接，不要使用此选项，否则会出现新建链接被RST的情况。

这是因为NAT设备后的多个地址使用了同一个nat后的地址，而Server端如果发现小于一定时间间隔的新建链接，认为是错误的，会RST掉。
**** tcp_tw_reuse = 0
重新利用 =TIME_WAIT= 状态的SOCKET，提高socket的使用率，避免耗尽。依赖 =tcp_timestamps= option来防止冲突，保证正确性。
**** tcp_timestamps = 0
=tcp_tw_recycle= 与 =tcp_tw_reuse= 都依赖此特性，这个选项是让通信双方都加上时间戳，能够避免冲突。
**** nf_conntrack_tcp_timeout_time_wait
=time_wait= 时长
**** tcp_max_tw_buckets
最大tw状态的链接数，超过这个数字，tw的状态链接被直接丢弃。设置这个值为了防止攻击造成SOCKET被大量 =TIME_WAIT= 占用。

*** 缓冲区
**** tcp_mem
tcp 内存总页面数量，分别是［low，watermark，hight］，这是全局内存的限制，在boot time计算得到。
**** net.core.rmem_default
读缓冲的大小 —— per connection
**** net.core.rmem_max
最大值 —— per connection
**** net.core.wmem_default
写缓冲的大小
**** net.core.wmem_max
最大值
**** tcp_rmem
tcp receive buffer size -- Per connection.
**** tcp_wmem
tcp send buffer size -- Per connection.
*** Keepalive
**** tcp_keepalive_time
多久没有数据就开始进行probe来探测链接的活跃
**** tcp_keepalive_intvl
probe 重试间隔
**** tcp_keepalive_probes
连续探测多少次都失败后就认为链接断裂了。然后关闭。
*** port
**** ip_local_port_range
本地(local)端口范围，每个主动发起的tcp链接，就会选择一个端口来与远端链接，如果端口都用完了，就建立链接失败。
**** ip_local_reserved_ports
保留的本地端口，在选择端口的时候，排除这些端口。这些端口一般给本地的服务器程序预留。从而避免被client类型程序占用。
